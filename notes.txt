#Run Docker command but destroys the container ones task is completed.
docker-compose run --rm scheduler python scripts/{file_name}

#Start the container and make it run continously
docker-compose up -d

#initialize the database
docker-compose run --rm webserver airflow db init

#Create a admin user
docker-compose run --rm webserver airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin

#Enter Postgrees db
docker-compose exec postgres psql -U airflow -d airflow

#Get all tables 
\dt

#Get Rows
SELECT COUNT(*) FROM raw_fires;


#env
NASA_API_KEY=your_nasa_key_here
# --- AWS CONFIG ---
AWS_ACCESS_KEY_ID=paste_your_access_key_here
AWS_SECRET_ACCESS_KEY=paste_your_secret_key_here
AWS_DEFAULT_REGION=us-east-1
S3_BUCKET_NAME=wildfire-lake-[yourname]-[number]